name: Collect Schumann Data

on:
  schedule:
    - cron: '0 * * * *'  # –ö–∞–∂–¥—ã–π —á–∞—Å
  workflow_dispatch:

jobs:
  schumann:
    runs-on: ubuntu-latest

    steps:
      - name: üì• Checkout repo
        uses: actions/checkout@v3

      - name: üêç Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: üì¶ Install dependencies
        run: |
          pip install -r requirements.txt
          pip install beautifulsoup4 requests

      - name: üöÄ Fetch Schumann point
        env:
          TELEGRAM_TOKEN: ${{ secrets.TELEGRAM_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.CHANNEL_ID }}
        run: |
          python - <<EOF
          import json
          import time
          import requests
          import re
          from pathlib import Path
          from bs4 import BeautifulSoup

          def send_telegram_message(token, chat_id, message):
              if not token or not chat_id:
                  print("Telegram token or chat_id missing")
                  return
              try:
                  url = f"https://api.telegram.org/bot{token}/sendMessage"
                  data = {"chat_id": chat_id, "text": message}
                  response = requests.post(url, data=data)
                  response.raise_for_status()
                  print("Telegram notification sent")
              except Exception as e:
                  print(f"Failed to send Telegram notification: {e}")

          def _fetch_schumann_data(url, attempts=5, backoff=2.0, timeout=45):
              for i in range(attempts):
                  try:
                      response = requests.get(url, timeout=timeout, headers={"User-Agent": "VayboMeter/1.0"})
                      response.raise_for_status()
                      data = response.text
                      print(f"Raw response from {url} (first 200 chars): {data[:200]}...")
                      if data:
                          print(f"Success: Got data from {url}")
                          return data
                      print(f"Retry {i+1}/{attempts} for {url} after {backoff**i}s")
                      time.sleep(backoff**i)
                  except Exception as e:
                      print(f"Retry {i+1}/{attempts} failed for {url}: {e}")
                      time.sleep(backoff**i)
              print(f"All attempts failed for {url}")
              return ""

          try:
              # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
              freq = None
              amp = None

              # –ü–∞—Ä—Å–∏–Ω–≥ SpaceWeatherLive
              if not (freq and amp):
                  raw_html = _fetch_schumann_data("https://www.spaceweatherlive.com/")
                  if raw_html:
                      soup = BeautifulSoup(raw_html, "html.parser")
                      all_text = " ".join(soup.stripped_strings)
                      print(f"Searching text on SpaceWeatherLive: {all_text[:200]}...")
                      freq_match = re.search(r"(\d+\.?\d*)\s*Hz", all_text)
                      amp_match = re.search(r"(\d+\.?\d*)\s*nT", all_text)
                      freq = freq_match.group(1) if freq_match else None
                      amp = amp_match.group(1) if amp_match else None
                      print(f"Parsed from SpaceWeatherLive: freq={freq}, amp={amp}")

              # –ü–∞—Ä—Å–∏–Ω–≥ NOAA API
              if not (freq and amp):
                  try:
                      response = requests.get("https://services.swpc.noaa.gov/products/geospace/geomagnetic-indices.json")
                      response.raise_for_status()
                      data = response.json()
                      print(f"NOAA API response (first 200 chars): {str(data)[:200]}...")
                      # –ü—Ä–∏–º–µ—Ä: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–ø–∏—Å–∏
                      if len(data) > 1:
                          last_entry = data[-1]
                          # –ò—â–µ–º –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á–∞—Å—Ç–æ—Ç—É –∏–ª–∏ –∞–º–ø–ª–∏—Ç—É–¥—É
                          json_text = json.dumps(last_entry)
                          freq_match = re.search(r"(\d+\.?\d*)\s*Hz", json_text)
                          amp_match = re.search(r"(\d+\.?\d*)\s*nT", json_text)
                          freq = freq_match.group(1) if freq_match else None
                          amp = amp_match.group(1) if amp_match else None
                          print(f"Parsed from NOAA API: freq={freq}, amp={amp}")
                  except Exception as e:
                      print(f"Failed to fetch NOAA API: {e}")

              # –ü–∞—Ä—Å–∏–Ω–≥ HeartMath GCI
              if not (freq and amp):
                  raw_html = _fetch_schumann_data("https://www.heartmath.org/gci/")
                  if raw_html:
                      soup = BeautifulSoup(raw_html, "html.parser")
                      all_text = " ".join(soup.stripped_strings)
                      print(f"Searching text on HeartMath GCI: {all_text[:200]}...")
                      freq_match = re.search(r"(\d+\.?\d*)\s*Hz", all_text)
                      amp_match = re.search(r"(\d+\.?\d*)\s*nT", all_text)
                      freq = freq_match.group(1) if freq_match else None
                      amp = amp_match.group(1) if amp_match else None
                      print(f"Parsed from HeartMath GCI: freq={freq}, amp={amp}")

              if not (freq and amp):
                  # Fallback –Ω–∞ –∫—ç—à
                  cache = Path("schumann_hourly.json")
                  if cache.exists():
                      arr = json.loads(cache.read_text())
                      if arr:
                          last = arr[-1]
                          freq, amp = last["freq"], last["amp"]
                          print("Using cached data:", last)
                      else:
                          print("Cache exists but is empty")
                  else:
                      print("No cache file found")

              if freq and amp:
                  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ—á–∫—É
                  rec = {"ts": int(time.time()), "freq": float(freq), "amp": float(amp)}
                  cache = Path("schumann_hourly.json")
                  arr = json.loads(cache.read_text()) if cache.exists() else []
                  arr.append(rec)
                  cutoff = int(time.time()) - 7*24*3600
                  arr = [r for r in arr if r["ts"] >= cutoff]
                  cache.write_text(json.dumps(arr, ensure_ascii=False))
                  print("Saved Schumann point:", rec)
                  # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∞–Ω–æ–º–∞–ª–∏—è—Ö
                  if float(freq) > 8.0 or float(amp) > 100.0:
                      send_telegram_message(
                          "${{ env.TELEGRAM_TOKEN }}",
                          "${{ env.TELEGRAM_CHAT_ID }}",
                          f"üö® High Schumann! Freq: {freq} Hz, Amp: {amp}"
                      )
              else:
                  print("No valid freq/amp data received, even from cache")
          except Exception as e:
              print(f"Error fetching Schumann data: {e}")
              send_telegram_message(
                  "${{ env.TELEGRAM_TOKEN }}",
                  "${{ env.TELEGRAM_CHAT_ID }}",
                  f"‚ö†Ô∏è Schumann script error: {e}"
              )
          EOF

      - name: üóÇÔ∏è Commit cache
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          commit_message: "schumann: add hourly point"
          file_pattern: "schumann_hourly.json"